{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, concatenate, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import MeanIoU\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the U-Net model\n",
    "def unet_model(input_size=(128, 128, 1)):\n",
    "    inputs = Input(input_size)\n",
    "\n",
    "    # Encoder\n",
    "    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D((2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D((2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    pool3 = MaxPooling2D((2, 2))(conv3)\n",
    "\n",
    "    conv4 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool3)\n",
    "    conv4 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "    pool4 = MaxPooling2D((2, 2))(drop4)\n",
    "\n",
    "    # Bottleneck\n",
    "    conv5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(pool4)\n",
    "    conv5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "    # Decoder\n",
    "    up6 = Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(drop5)\n",
    "    merge6 = concatenate([drop4, up6], axis=3)\n",
    "    conv6 = Conv2D(512, (3, 3), activation='relu', padding='same')(merge6)\n",
    "    conv6 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv6)\n",
    "\n",
    "    up7 = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv6)\n",
    "    merge7 = concatenate([conv3, up7], axis=3)\n",
    "    conv7 = Conv2D(256, (3, 3), activation='relu', padding='same')(merge7)\n",
    "    conv7 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv7)\n",
    "\n",
    "    up8 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv7)\n",
    "    merge8 = concatenate([conv2, up8], axis=3)\n",
    "    conv8 = Conv2D(128, (3, 3), activation='relu', padding='same')(merge8)\n",
    "    conv8 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv8)\n",
    "\n",
    "    up9 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv8)\n",
    "    merge9 = concatenate([conv1, up9], axis=3)\n",
    "    conv9 = Conv2D(64, (3, 3), activation='relu', padding='same')(merge9)\n",
    "    conv9 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv9)\n",
    "    conv9 = Conv2D(2, (3, 3), activation='relu', padding='same')(conv9)\n",
    "    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=conv10)\n",
    "\n",
    "    return model\n",
    "\n",
    "# Define the data generators for preprocessing\n",
    "def create_data_generators(train_images, train_masks, batch_size=32):\n",
    "    data_gen_args = dict(horizontal_flip=True,\n",
    "                          vertical_flip=True,\n",
    "                          rotation_range=90,\n",
    "                          zoom_range=0.2)\n",
    "\n",
    "    image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "    # Provide the same seed for reproducibility\n",
    "    seed = 1\n",
    "    image_generator = image_datagen.flow(train_images, batch_size=batch_size, seed=seed)\n",
    "    mask_generator = mask_datagen.flow(train_masks, batch_size=batch_size, seed=seed)\n",
    "\n",
    "    return zip(image_generator, mask_generator)\n",
    "\n",
    "# Compile and train the model\n",
    "def train_model(train_images, train_masks, val_images, val_masks, batch_size=32, epochs=50):\n",
    "    model = unet_model(input_size=(128, 128, 1))\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=1e-4),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=[MeanIoU(num_classes=2)])\n",
    "\n",
    "    train_gen = create_data_generators(train_images, train_masks, batch_size=batch_size)\n",
    "\n",
    "    history = model.fit(train_gen,\n",
    "                        validation_data=(val_images, val_masks),\n",
    "                        steps_per_epoch=len(train_images) // batch_size,\n",
    "                        epochs=epochs)\n",
    "\n",
    "    return model, history\n",
    "\n",
    "# Visualization of results\n",
    "def visualize_results(model, test_images, test_masks):\n",
    "    predictions = model.predict(test_images)\n",
    "\n",
    "    for i in range(5):  # Visualize first 5 test images\n",
    "        plt.figure(figsize=(12, 6))\n",
    "\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.title('Input Image')\n",
    "        plt.imshow(test_images[i].reshape(128, 128), cmap='gray')\n",
    "\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.title('Ground Truth Mask')\n",
    "        plt.imshow(test_masks[i].reshape(128, 128), cmap='gray')\n",
    "\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.title('Predicted Mask')\n",
    "        plt.imshow(predictions[i].reshape(128, 128), cmap='gray')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "# Load and preprocess your dataset\n",
    "# Example: Assume train_images, train_masks, val_images, val_masks are numpy arrays\n",
    "# train_images = ...\n",
    "# train_masks = ...\n",
    "# val_images = ...\n",
    "# val_masks = ...\n",
    "\n",
    "# Uncomment below lines and use the actual dataset\n",
    "# model, history = train_model(train_images, train_masks, val_images, val_masks)\n",
    "# visualize_results(model, val_images, val_masks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, concatenate, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import MeanIoU\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the U-Net model\n",
    "def unet_model(input_size=(128, 128, 1)):\n",
    "    inputs = Input(input_size)\n",
    "\n",
    "    # Encoder\n",
    "    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D((2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D((2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    pool3 = MaxPooling2D((2, 2))(conv3)\n",
    "\n",
    "    conv4 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool3)\n",
    "    conv4 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "    pool4 = MaxPooling2D((2, 2))(drop4)\n",
    "\n",
    "    # Bottleneck\n",
    "    conv5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(pool4)\n",
    "    conv5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "    # Decoder\n",
    "    up6 = Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(drop5)\n",
    "    merge6 = concatenate([drop4, up6], axis=3)\n",
    "    conv6 = Conv2D(512, (3, 3), activation='relu', padding='same')(merge6)\n",
    "    conv6 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv6)\n",
    "\n",
    "    up7 = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv6)\n",
    "    merge7 = concatenate([conv3, up7], axis=3)\n",
    "    conv7 = Conv2D(256, (3, 3), activation='relu', padding='same')(merge7)\n",
    "    conv7 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv7)\n",
    "\n",
    "    up8 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv7)\n",
    "    merge8 = concatenate([conv2, up8], axis=3)\n",
    "    conv8 = Conv2D(128, (3, 3), activation='relu', padding='same')(merge8)\n",
    "    conv8 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv8)\n",
    "\n",
    "    up9 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv8)\n",
    "    merge9 = concatenate([conv1, up9], axis=3)\n",
    "    conv9 = Conv2D(64, (3, 3), activation='relu', padding='same')(merge9)\n",
    "    conv9 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv9)\n",
    "    conv9 = Conv2D(2, (3, 3), activation='relu', padding='same')(conv9)\n",
    "    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=conv10)\n",
    "\n",
    "    return model\n",
    "\n",
    "# Define the data generators for preprocessing\n",
    "def create_data_generators(train_images, train_masks, batch_size=32):\n",
    "    data_gen_args = dict(horizontal_flip=True,\n",
    "                          vertical_flip=True,\n",
    "                          rotation_range=90,\n",
    "                          zoom_range=0.2)\n",
    "\n",
    "    image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "    # Provide the same seed for reproducibility\n",
    "    seed = 1\n",
    "    image_generator = image_datagen.flow(train_images, batch_size=batch_size, seed=seed)\n",
    "    mask_generator = mask_datagen.flow(train_masks, batch_size=batch_size, seed=seed)\n",
    "\n",
    "    return zip(image_generator, mask_generator)\n",
    "\n",
    "# Compile and train the model\n",
    "def train_model(train_images, train_masks, val_images, val_masks, batch_size=32, epochs=50):\n",
    "    model = unet_model(input_size=(128, 128, 1))\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=1e-4),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=[MeanIoU(num_classes=2)])\n",
    "\n",
    "    train_gen = create_data_generators(train_images, train_masks, batch_size=batch_size)\n",
    "\n",
    "    history = model.fit(train_gen,\n",
    "                        validation_data=(val_images, val_masks),\n",
    "                        steps_per_epoch=len(train_images) // batch_size,\n",
    "                        epochs=epochs)\n",
    "\n",
    "    return model, history\n",
    "\n",
    "# Visualization of results\n",
    "def visualize_results(model, test_images, test_masks):\n",
    "    predictions = model.predict(test_images)\n",
    "\n",
    "    for i in range(5):  # Visualize first 5 test images\n",
    "        plt.figure(figsize=(12, 6))\n",
    "\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.title('Input Image')\n",
    "        plt.imshow(test_images[i].reshape(128, 128), cmap='gray')\n",
    "\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.title('Ground Truth Mask')\n",
    "        plt.imshow(test_masks[i].reshape(128, 128), cmap='gray')\n",
    "\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.title('Predicted Mask')\n",
    "        plt.imshow(predictions[i].reshape(128, 128), cmap='gray')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "# Load and preprocess your dataset\n",
    "# Example: Assume train_images, train_masks, val_images, val_masks are numpy arrays\n",
    "# train_images = ...\n",
    "# train_masks = ...\n",
    "# val_images = ...\n",
    "# val_masks = ...\n",
    "\n",
    "# Uncomment below lines and use the actual dataset\n",
    "# model, history = train_model(train_images, train_masks, val_images, val_masks)\n",
    "# visualize_results(model, val_images, val_masks)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
